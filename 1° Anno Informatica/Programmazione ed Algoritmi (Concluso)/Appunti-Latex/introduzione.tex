\section{Introduzione}
\subsection{Puntatori}
Gli indirizzi di memoria delle variabili sono interi (rappresentati in esadecimale) che contano i byte a partire dalla posizione 0x0000000. Gli indirizzi di memoria possono essere memorizzati in variabili come ogni altro intero.
\begin{definition}[Puntatori]
Definiamo le variabili che memorizzano indirizzi di memoria come \textbf{puntatori}.
\end{definition}
\subsubsection{Operatori sui puntatori}
Sono due i principali operatori che possono essere usai con i puntatori.
\begin{itemize}
    \item \textbf{(\&)} \hspace{.1cm} - \hspace{.1cm} \textbf{Operatore indirizzo}. L'operatore di indirizzo è unario\footnote{Unario vuol dire che agisce su una sola variabile} e restituisce l'indirizzo di memoria dell'operando (può essere anche un altro puntatore, in questo caso restituisce l'indirizzo in cui è memorizzato il puntatore, cioè l'indirizzo di memoria di una variabile).
    \item \textbf{(*)} \hspace{.1cm} - \hspace{.1cm} \textbf{Operatore di indirezione o dereferenziazione}. L'operatore di indirezione è unario e restituisce il valore dell'oggetto a cui punta l'operanda. 
\end{itemize}

\begin{note}
Nota che \& e * sono uno l'inverso dell'altro, quindi: \&*aPtr == *\&aPtr.
\end{note}

\begin{example}\label{esempio-1}
Di seguito un esempio di utilizzo di puntatori con anche i vari operatori.
\end{example}
\vspace{2pt}
\begin{lstlisting}[language=Javascript, caption=Esempio puntatori e operatori sui puntatori]
var a:Character = 'z', b:Character = 'h';
ref aPtr:Character = nil                        //0x0
aPtr = 0;                                       //0x0
aPtr = &a;                                      
print(&a, aPtr);                                //0x7ffeefbff60f, 0x7ffeefbff60f
print(*aPtr, a);                                //z, z
print(&aPtr);                                   //0x7ffeefbff60f
*aPtr = b;
print(*aPtr, a, b);                             //h, h, h
print(&b, &a, aPtr);                            // 3 volte 0x7ffeefbff60f
ref altro_aPtr:Character = &a;                  
print(altro_aPtr, *altro_aPtr);                 //0x7ffeefbff60f, h
\end{lstlisting}
\vspace{3pt}

\hspace{-15pt}\underline{Descrizione esempio:} Osservando l'esempio sopra \ref{esempio-1} possiamo vedere alle righe (11) e (12) che abbiamo una dichiarazione di un nuovo puntatore che punta alla stessa cella di memoria di "aPtr", abbiamo quindi più di un puntatore che punta alla stessa variabile.\\\\
Possiamo vedere che le locazioni di memoria sono numeri interi che individuano la posizione della cella di memoria (sono numeri interi scritti in esadecimale, ma sempre numeri interi), è quindi possibili effettuare operazioni aritmetiche sui puntatori, cioè è possibile manipolare tramite operazioni aritmetiche le locazioni.\\
\begin{example}
Se per esempio prendiamo un ambiente ed una memoria così composti:
\end{example}
\begin{wrapfigure}[10]{r}{8cm}
    \vspace{-5pt}
    \centering
    \includegraphics[width=7cm]{images/esempio-puntatori-1.png}
    \caption{Operazioni algebriche su puntatori}
\end{wrapfigure}

$\rho = [(aPtr, l2)]$ \: \: $\sigma = [(l1,13), (l2,23)]$\\ \\
Abbiamo quini un puntatore "aPtr" che punta alla locazione l1, il quale contiene il numero 13, più una posizione l2, successiva alla l1, che contiene 23.\\ Se ipotizziamo che il nostro sistemi archivi le informazioni con una base di 32 bit \footnote{Questo vuol dire che ogni vaore è salvato con 32 bit, quindi ogni 32 ci sarà un nuovo valore archiviato} ed andiamo a sommare 32 a "aPtr" succederà che ci sposteremo di 32 posti nella memoria raggiungendo l2, quindi "aPtr" = l2.

\subsection{Strutture dati}
\begin{definition}[Struttura dati]
Una \textbf{struttura dati} è un formato che serve ad organizzare e memorizzare dati in modo da renderli agevolmente disponibili agli algoritmi che li manipolano.
\end{definition}
\hspace{-15pt}Alcune caratteristiche delle strutture dati:
\begin{itemize}
    \item Una struttura dati è detta \textbf{omogenea} se contiene dati tutti dello stesso tipo. Altrimenti è \textbf{disomogenea}.
    \item Una struttura dati è \textbf{statica} se la sua dimensione non varia durante l'esecuzione del programma. Altrimenti è detta \textbf{dinamica}.
    \item Una struttura dati è \textbf{lineare} se i dati sono organizzati come sequenze di valori. Altrimenti è detta \textbf{non lineare}.
\end{itemize}
Una struttura dati è inoltre caratterizzata dalle operazioni elementari disponibili per inserire, reperire e modificare i dati che memorizza.

\subsection{Notazione asintotica}
Quando scriviamo un algoritmo, per calcolare il costo di tale algoritmo, bisogna fare una serie di assunzioni sulla macchina astratta su cui lavoriamo:
\begin{itemize}
    \item L'accesso alle celle di memoria avviene in tempo costante.
    \item Le operazioni elementari avvengono in tempo costante:
    \begin{itemize}
    	\item Operazioni aritmetiche e logiche della ALU
    	\item Gli assegnamenti
    	\item I controlli del flusso (salti, assegnamento al registro PC)
    \end{itemize}
    
\end{itemize}
Per calcolare il costo degli algoritmi si possono utilizzare due modelli:
\begin{enumerate}
    \item \textbf{Word model}: tutti i dati occupano solo una cella di memoria.
    \item \textbf{Bit model}: unità elementare di memoria \emph{bit}, si usa quando le grandezze sono troppo grandi.
\end{enumerate}

\hspace{-15pt}Esistono una serie di parametri da \textbf{analizzare} quando scriviamo una algoritmo. Essi permettono di garantire il suo corretto funzionamento e la sua ottimizzazione. Sono i seguenti:
\begin{itemize}
    \item \textbf{Complessità}: ovvero l'analisi dell'utilizzo delle risorse: 
    \begin{itemize}
    	\item tempo di esecuzione
    	\item spazio di memoria per i dati in ingresso e in uscita. Viene rappresentato astrattamente dal numero di celle di memoria (word model)
    	\item banda di comunicazione (per esempio nel caso il calcolo sia distribuito)
    \end{itemize}
	Non sarà quasi mai possibile avere un programma che è sia efficiente in termini di tempo che in di spazio (\emph{coperta corta}).
    \item \textbf{Correttezza}: Indica se l'algoritmo fa quello per cui è stato progettato. Si esegue in due modi:
    \begin{itemize}
    	\item \underline{dimostrazione formale} la quale permette di dimostrare la correttezza risolvendo tutte le istanze del problema
    	\item \underline{ispezione formale} nella quale si usano metodi come il \textbf{testing} o il \textbf{profiling}. Il primo prevede di provare il programma nelle situazioni critiche, il secondo analizza il tempo che la CPU impiega per elaborare una determinata parte del programma.
    \end{itemize}
    \item \textbf{Semplicità}: Indica se l'algoritmo è facile da capire e manutenere. Un algoritmo è semplice quando usa identificatori significativi, quando è ben commentato, se usa strutture dati adeguate e se rispetta gli standard.
\end{itemize}

\begin{definition}[Complessità di un problema]
    La complessità di un problema $P$ è la complessità del miglior algoritmo $A$ che lo risolve.
\end{definition}
Per trovare la complessità del problema partiamo dal fatto che, dato un algoritmo $A$, la complessità di $A$ determina un limite superiore alla complessità di $P$ (cioè quando si verifica il caso peggiore uso $A$ per risolvere $P$).\\
Se riusciamo a determinare un limite inferiore $g(n)$ per $P$, per ogni algoritmo $A$ che risolve $P$ ho che $A \in \Omega(g(n))$, dove $g(n)$ è il minimo numero di operazione che posso impiegare per risolvere $P$. Quindi possiamo dire che:
\begin{center}
    $A \in \Theta(g(n)) \Longrightarrow A$ ottimo \footnote{Ricorda che dire che $A \in \Theta(g(n))$ vuol dire che $A \in O(g(n))$ e $A \in \Omega(g(n))$}
\end{center}
Per fare ciò bisogna anche andare a calcolare il limite inferiore del caso pessimo, e ciò è possibile tramite 3 metodi: la \textbf{dimensione dei dati}, gli \textbf{eventi contabili} e gli \textbf{alberi decisionali}.

\begin{itemize}
    \item \textbf{Dimensioni dei dati:} Se la soluzione di un problema richiede l'esame di tutti i dati in input, allora $\Omega(n)$ è un limite inferiore.
    \begin{example}
    	Sommare tutti gli elementi di un array.
    \end{example}
\end{itemize}
\begin{itemize}
    \item \textbf{Eventi contabili:} Se la soluzione di un problema richiede la ripetizione di un certo evento, allora il numero di volte che l'evento si ripete (moltiplicato per il suo costo) è un limite.
    \begin{example}
    	Se voglio costruire un array i cui elementi sono la radice quadrata degli elementi di un array dato, dovrò fare un ciclo che scorre l'array dato e applica la radice quadrata. Gli eventi contabili sono quindi il numero di iterazioni.
    \end{example}
\end{itemize}

\subsection{Big-O notation}
La notazione Big-O ha molteplici scopi della scrittura di un algoritmo.
\begin{itemize}
    \item Serve a rappresentare la complessità relativa di un algoritmo.
    \item Descrive le prestazioni di un algoritmo e come queste scalano al cresce dei dati in input.
    \item Descrive un limite superiore al tasso di crescita di na funzione ed il caso peggiore.
\end{itemize}

\subsubsection{Limite superiore asintotico}
\begin{definition}[Limite superiore asintotico]
Il limite superiore asintotico \footnote{\emph{Asintotico} indica che la definizione deve essere valida solo da un certo punto in poi scelto arbitrariamente.} si definisce come:
\begin{center}
    $O(g(n)) = \{f(n) \mid: \exists c, n_0 > 0 . \forall n > n_0, 0 \leq f(n) \leq c \cdot g(n)\}$
\end{center}
\end{definition}
\hspace{-15pt}Si scrive come $f(n) \in O(g(n))$ oppure $f(n) = O(g(n))$ e si legge $f(n)$ è nell'ordine $O$ grande di $g(n)$.
\begin{note}
	Abbiamo disegnato solo il primo quadrante perché sia i dati in input che le operazioni da eseguire saranno sempre in numero positivo.
\end{note}
\begin{example}
Esempio di calcolo del limite superiore asintotico
\end{example}
\begin{wrapfigure}[7]{l}{8cm}
    \vspace{-15pt}
    \centering
    \includegraphics[width=6cm]{images/limite-superiore-asintotico.png}
    \vspace{-5pt}
    \caption{Limite superiore asintotico}
\end{wrapfigure}
Prendiamo due funzioni e determiniamo i punti $n_0$ e $c$ per cui è soddisfatta la definizione.
\begin{center}
    \vspace{-5pt}
    $f(n) = 3n^2 + 5$\hspace{30pt}$g(x)=n^2$
\end{center}
Stabiliamo un $c = 4$ e $n_0 = 3$.
\begin{enumerate}
    \item $4 \cdot g(n) = 4n^2 = 3n^2 + n^2 $
    \item $3n^2 + n^2 \geq 3n^2 + 9 $ (per ogni $n \geq 3$)
    \item $3n^2 + 9 > 3n^2+5 \Longrightarrow 4 \cdot g(n) > f(n)$
\end{enumerate}

\subsubsection{Limite inferiore asintotico}
\begin{definition}[Limite inferiore asintotico]
Il limite inferiore asintotico si definisce come:
\begin{center}
    $\Omega(g(n)) = \{f(n) \mid \exists c, n_0 > 0 . \forall n > n_0, 0 \leq c \cdot g(n) \leq f(n) \}$
\end{center}
\end{definition}
\hspace{-15pt}Si scrive come $f(n) \in \Omega(g(n))$ oppure $f(n) = \Omega(g(n))$ e si legge $f(n)$ è nell'ordine $\Omega$ grande di $g(n)$. Indica che quell'algoritmo non potrà mai fare di meglio.
\begin{example}
Esempio di calcolo del limite inferiore asintotico. Prendiamo due funzioni e determiniamo i punti $n_0$ e $c$ per cui è soddisfatta la definizione.
\end{example}
\begin{wrapfigure}[6]{r}{8cm}
    \vspace{-15pt}
    \centering
    \includegraphics[width=6cm]{images/limite-inferiore-asintotico.png}
    \vspace{-5pt}
    \caption{Limite superiore asintotico}
\end{wrapfigure}

$f(n) = \frac{n^2}{2}-7$ \: \: \: $g(x)=n^2$\\
Stabiliamo un $c = \frac{1}{4}$ e $n_0 = 6$.
\begin{enumerate}
    \item $\frac{1}{4} \cdot g(n) = \frac{n^2}{4} = \frac{n^2}{2} - \frac{n^2}{4}$
    \item $\frac{n^2}{2} - \frac{n^2}{4} \leq \frac{n^2}{2} - 9 $ (per ogni $n \geq 6$)
    \item $\frac{n^2}{2} - 9 > \frac{n^2}{2}-7 \Longrightarrow \frac{1}{4} \cdot g(n) < f(n)$
\end{enumerate}

\subsubsection{Limite asintotico stretto}
\begin{definition}[Limite inferiore asintotico]
Il limite asintotico stretto si definisce come:
\begin{center}
    $\Theta(g(n)) = \{f(n) \: |\: \exists c_1, c_2, n_0 > 0 \: . \: \forall n > n_0, 0 \leq c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n) \}$
\end{center}
\end{definition}
\begin{wrapfigure}[5]{r}{8cm}
    \vspace{-10pt}
    \centering
    \includegraphics[width=6cm]{images/limite-asintotico-stretto.png}
    \vspace{-5pt}
    \caption{Limite asintotico stretto}
\end{wrapfigure}
Si scrive come $f(n) \in \Theta(g(n))$ oppure $f(n) = \Theta(g(n))$ e si legge $f(n)$ è nell'ordine $\Theta$ grande di $g(n)$.\\\\
Dalla definizione deriva che:\\
$f(n) \in \Theta(g(n)) \Longleftrightarrow f(n) \in \Omega(g(n)) \land f(n) \in O(g(n))$\\\\\\


\subsubsection{Teoremi sulla notazione asintotica}
\begin{theorem}
Per ogni $f(n)$ e $g(n)$ vale che:
\begin{enumerate}
    \item $f(n) = O(g(n)) \Longleftrightarrow g(n) = \Omega(f(n))$
    \item Se $f_1(n) = O(f_2(n)) \land f_2(n) = O(f_3(n)) \Longrightarrow f_1(n) = O(f_3(n))$
    \item Se $f_1(n) = \Omega(f_2(n)) \land f_2(n) = \Omega(f_3(n)) \Longrightarrow f_1(n) = \Omega(f_3(n))$
    \item Se $f_1(n) = \Theta(f_2(n)) \land f_2(n) = \Theta(f_3(n)) \Longrightarrow f_1(n) = \Theta(f_3(n))$
    \item Se $f_1(n) = O(g_1(n)) \land f_2(n) = O(g_2(n)) \Longrightarrow O(f_1(n) + f_2(n)) = O(max\{g_1(n),g_2(n)\})$
    \item Se $f(n)$ è un polinomio di grafo $d \Longrightarrow f(n) = \Theta(n^d)$
\end{enumerate}
\end{theorem}

\subsubsection{Limite superiore asintotico non stretto}
\begin{definition}[Limite superiore asintotico non stretto]
Il limite superiore asintotico non stretto si definisce come:
\begin{center}
    $o(g(n)) = \{f(n) \mid \forall c \exists n_0 > 0 . \forall n > n_0, 0 \leq f(n) \leq c \cdot g(n) \}$
\end{center}
\end{definition}
\hspace{-15pt}Si scrive come $f(n) \in o(g(n))$ oppure $f(n) = o(g(n))$ e si legge $f(n)$ è nell'ordine $o$ piccolo di $g(n)$.\\
$f(n)$ è limitata superiormente da $g(n)$, ma non la raggiunge mai.\\
\begin{wrapfigure}[7]{l}{7cm}
    \vspace{-15pt}
    \centering
    \includegraphics[width=6.5cm]{images/limite-superiore-asintotico-non-stretto.png}
    \vspace{-5pt}
    \caption{Limite superiore non stretto}
\end{wrapfigure}

\vspace{-15pt}
E immediato dalla definizione che:
\begin{center}
    $o(g(n)) \Longrightarrow O(g(n))$
\end{center}
Non vale il viceversa: 
\begin{center}
    $2n^2 \in O(n^2) \land 2n^2 \notin o(n^2)$
\end{center}
Definizione alternativa:
\begin{center}
    $f(n) \in o(g(n)) \Longleftrightarrow \lim\limits_{n\to \infty}\frac{g(n)}{f(n)} = \infty$
\end{center}

\subsubsection{Limite inferiore asintotico non stretto}
\begin{definition}[Limite inferiore asintotico non stretto]
Il limite inferiore asintotico non stretto si definisce come:
\begin{center}
    $\omega(g(n)) = \{f(n) \mid \forall c \: \exists n_0 > 0 \: . \: \forall n > n_0, 0 \leq c \cdot g(n) \leq f(n) \}$
\end{center}
\end{definition}
\hspace{-15pt}Si scrive come $f(n) \in \omega(g(n))$ oppure $f(n) = \omega(g(n))$ e si legge $f(n)$ è nell'ordine $\omega$ piccolo di $g(n)$.\\
$f(n)$ è limitata inferiormente da $g(n)$, ma non la raggiunge mai.\\
\begin{wrapfigure}[7]{l}{7cm}
    \vspace{-15pt}
    \centering
    \includegraphics[width=6.5cm]{images/limite-inferiore-asintotico-non-stretto.png}
    \vspace{-5pt}
    \caption{Limite asintotico stretto}
\end{wrapfigure}

\vspace{-15pt}
E immediato dalla definizione che:
\begin{center}
    $\omega(g(n)) \Longrightarrow \Omega(g(n))$
\end{center}
Non vale il viceversa: 
\begin{center}
    $\frac{1}{5}n^2 \in \Omega(n^2) \land \frac{1}{2}n^2 \notin \omega(n^2)$
\end{center}
Definizione alternativa:
\begin{center}
    $f(n) \in \omega(g(n)) \Longleftrightarrow \lim\limits_{n\to \infty}\frac{g(n)}{f(n)} = 0$
\end{center}
