% !TeX spellcheck = it_IT
\newpage
\section{Input output}
Quando andiamo a parlare dei sistemi di input output le cose principale da considerare sono i 
dispositivi di I/O i device controller, i buses, la gestione dell'I/O ed i device drivers.

\begin{figure}[!h]
    \centering
    \includegraphics[width=13cm]{images/input-output-iodevice.png}
    \caption{Input/output e I/O devices}
\end{figure}

\hspace{-15pt}Solitamente le operazioni di I/O hanno un grosso impatto sul tempo di esecuzione dei programmi.
Supponiamo per esempio di andare a calcolare il tempo di esecuzione con \(T_{exe} = T_{cpu} + T_{I/O} = \frac{1}{10}T_{cpu}\) perciò
\(T_{exe} = \frac{11}{10}T_{cpu}\).\\\\
\hspace{-15pt}Se andiamo ad aumentare il tempo \(T_{cpu}\) di 10 volte lasciando inalterato il \(T_{I/O}\) abbiamo
un \(T_{cpu}^{enhanced} = \frac{1}{10} T_{cpu}\) così \(T_{exe} = \frac{1}{10}T_{cpu} + \frac{1}{10}T_{cpu} = \frac{1}{5}T_{cpu}\)
Consideriamo copi che l'aumento di velocià uguale a: \[\frac{T_{exe} \text{before enhancmente}}{T_{exe} \text{after enhancmente}} = \frac{11}{5} = 5.5\]

\subsection{Legge di Amdahl}
Proposto da Gene Amdahl nel 1967. Si occupa della potenziale velocità massima raggiungibile da un programma parallelo quando si aumenta il numero di processori da 1 a N.
Può essere applicato a qualsiasi processo di ottimizzazione. 
Si consideri un programma in cui solo la frazione f può essere ottimizzata (ad esempio, parallelizzata utilizzando N processori), mentre la frazione (1-f) rimane inalterata (ad esempio, è intrinsecamente sequenziale).
\[\text{Speedup} = \frac{\text{Tempo di esecuzione prima del miglioramento}}{\text{Tempo di esecuzione dopo il miglioramento}} = \frac{T(1- f) + Tf}{T(1 - f) + \frac{Tf}{N}} = \frac{1}{(1 - f) + \frac{f}{N}}\]

\begin{observation}
    L'accelerazione è vincolata dalla frazione sequenziale (1-f), cioè dalla parte del processo che non posso (o non sono in grado) di valorizzare!
\end{observation}

\hspace{-15pt}
Le prestazioni del sottosistema I/O sono molto importanti, ma non sono tutto. Altri aspetti importanti sono:
\begin{itemize}
    \item \textbf{Affidabilità} gestite da metriche del tempo medio al guasto (MTTF), prevenzione dei guasti (componenti migliori), tolleranza ai guasti (introduzione di un certo livello di ridondanza).
    \item \textbf{Disponibilità} invece gestite da Tempo medio di riparazione (MTTR), e dalla formula \(\frac{MTTF}{MTTF + MTTR}\)
\end{itemize}

\hspace{-15pt}I dispositivi I/O hanno due tipologie di porte: porte di controllo, e porte data.
\begin{itemize}
    \item Controllo: sia comandi che rapporti di stato, come diciamo al dispositivo cosa fare, come il dispositivo ci racconta le sue caratteristiche, come il dispositivo ci informa sullo stato operativo.
    \item Data: Alla/dalla memoria del dispositivo.
\end{itemize}

\vspace{-10pt}
\begin{figure}[!h]
    \centering
    \includegraphics[width=12cm]{images/generic-io-device.png}
    \caption{I/O device generico}
\end{figure}

\hspace{-15pt}I/O funzioni di controllo abbiamo invece il control and imting, la comunicazioni fra processi (command decoding, data exchange, status reporting, address recognition), comunicazione
fra i device, il data buffering (per ottimizare il trasferimento dei dati e compensare le differenze di velocità).

\subsection{Connessione bus}
Servono per il controllo del trasferimento da un dispositivo al processore:
\begin{enumerate}
    \item la CPU controlla lo stato del dispositivo del modulo I/O.
    \item Il controller I/O restituisce lo stato se pronta.
    \item La CPU richiede il trasferimento dei dati tramite un comando al controllore.
    \item Il controller I/O riceve i dati dal dispositivo periferico.
    \item il controller I/O trasferisce i dati al processore.
\end{enumerate}

\begin{wrapfigure}{r}{7cm}
    \vspace{-35pt}
    \centering
    \includegraphics[width=6cm]{images/io-controller-diagram.png}
    \caption{I/O device generico}
\end{wrapfigure}
Questi passaggi richiedono una o più azioni di arbitrato del bus per implementare il protocollo di comunicazione.
Andiamo ora a definire l'interconnesione fra bus, essa si definisce come una raccolta di linee di dati trattate insieme come un singolo segnale logico
utilizzato anche per indicare una raccolta condivisa di linee con più dispositivi connessi (chiamati rubinetti), si definiscono su essi alcuni fattori di prestazione: lunghezza fisica, numero di prese collegate.
\\\\Un bus è un mezzo di trasmissione condiviso, solo un dispositivo alla volta può trasmettere con successo. Il bus di sistema collega i principali componenti (processore, memoria, bus I/O), centinaia di linee separate, linee classificate in tre gruppi: dati, indirizzo, controllo.
\newpage

\noindent Alcuni tipi di bus sono:
\begin{itemize}
    \item \textbf{System bus} Collega processore e memoria, I/O interfacciato con adattatori: breve, pochi tocchi e quindi più veloce e larghezza di banda elevata, inoltre non è standard (ovvero specifico del sistema).
    \item \textbf{I/O bus} Connette dispositivi I/O, nessuna connessione diretta con processore e memoria: più tempo, più tocchi è uguale a più lentezza e larghezza di banda inferiore. E' uno standard di settore (ad es. ATA/SCSI).
    \item \textbf{Backplane bus} Connette CPU, memoria, dispositivi I/O. Lunghe, molti tocchi allora lento e larghezza di banda medio/bassa. Gestisce diversi dispositivi con diverse larghezze di banda ed è standard di settore.
\end{itemize}

\subsubsection{Bus design}
Il design di un bus si basa sul principio di soddisfare gli obbiettivi di avere un alta \textbf{performance}, \textbf{standardizzazione} e bassi costi. Per esempio 
il bus di sistema enfatizza le prestazioni, l'I/O e i bus backplain enfatizzano i costi e la standardizzazione.\\
I punti cruciali nel design di un bus sono:
\begin{itemize}
    \item I cavi sono \textbf{condivisi} o separati? I bus più ampi (maggiore larghezza di banda) sono più costosi e più suscettibili allo \emph{skew}.
    \item Come viene acquisito e rilasciato il \textbf{controllo} del bus? Tramite due metodologie:
    \begin{itemize}
    	\item  \emph{Atomic transactions}: fornisce una bassa utilizzazione ma anche una bassa complessità
    	\item \emph{Split-transactions}: le richieste/risposte possono essere intervallate; ciò significa che fornisce un utilizzo più elevato ma al costo di una complessità maggiore
    \end{itemize}
    \item I bus sono \textbf{sincronizzati}?
    \begin{itemize}
        \item \emph{Sincrono}. Tutti i dispositivi collegati al bus condividono lo stesso bus clock. Gli eventi si verificano all'estremità del segnale di clock. Un protocollo possibile è che al ciclo \(X\) l'unità di I/O scrive una richiesta READ sul bus; al ciclo \(X + \Delta\) l'unità può leggere i dati dal bus.
        \(\Delta\) è il tempo massimo per scrivere i dati sul bus da parte di un'unità collegata. Potenzialmente c'è il problema di skew dell'orologio. Viene principalmente utilizzata nei bus brevi (e.g. bus di sistema).
        \item \emph{Asincrono}. Il bus non ha il clock. Nessun disallineamento dell'orologio, si occupa di dispositivi con velocità diverse: può essere più lungo, quindi più lento. Richiede protocolli di \textbf{handshaking}. Un possibile protocollo (3 linee di controllo, 1 linea dati in cui i dati e l'indirizzo sono multiplexati):
        \begin{enumerate}
        	\item UIO1 scrive una richiesta READ (WRITE) ReadReq (WriteReq) nella linea di controllo e l'indirizzo nella linea dati
        	\item UIO2 legge il indirizzo e scrive un ACK nella linea di controllo a UIO13
        	\item UIO2 scrive i dati sul bus e scrive la riga DataReadycontrol per notificare UIO14
        	\item UIO1 legge i dati e invia un ACK nella linea di controllo a UIO2
        \end{enumerate}
    \end{itemize}
    \item Come si decide chi prende un bus per trasferire dati (\textbf{arbitraggio})? Le comunicazioni bus devono essere gestite da un protocollo di comunicazione. I due concetti principali sono:
    \begin{itemize}
        \item \textbf{Bus master}: un'unità che può far partire una richiesta ad un bus. La configurazione più semplice prevede solo un master ma di solito ce ne sono molteplici.
        \item \textbf{Arbitration}: il master viene scelto tra più richieste cercando di implementare la priorità e l'equità (prevenendo la starvation). C'è solo un master alla volta (tutti gli altri ascoltano il bus). Il ruolo dell'arbitro è gestire le richieste del bus e assegnare le sovvenzioni considerando le priorità e l'equità.Esistono due modi per implementare l'arbitro:
        \begin{itemize}
        	\item \textbf{Centralizzato}: un dispositivo dedicato (Arbiter) raccoglie le richieste e poi decide (potenziale problema di collo di bottiglia). Si può usare il metodo \emph{Daisy Chain}, non equo in quanto i dispositivi ad alta priorità intercettano quelli a bassa priorità. Un altro metodo è tramite linee di \emph{richiesta/risposta} indipendenti.
        	\item \textbf{Distribuito}: ogni dispositivo vede le richieste contemporaneamente e partecipa alla selezione del master successivo. Più complesso da realizzare e necessita di molte linee di controllo.
        \end{itemize}
    \end{itemize}
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=8.5cm]{images/daily-chain-arbitrain.png}
    \caption{Daily chain arbiter}
\end{figure}

\subsection{Gestione dell'I/O}
\subsubsection{Invio dei comandi ai dispositivi}
Solamente il sistema operativo può mandare comandi ai dispositivi di I/O ed il programmatore deve quindi utilizzare delle chiamate di sistema. Abbiamo due opzioni:
\begin{wrapfigure}{r}{5cm}
	\vspace{20px}
	\centering
	\includegraphics[width=4.5cm]{images/memory-mapped-io.png}
	\caption{Memory-mapped}
\end{wrapfigure}
\begin{itemize}
    \item \textbf{Istruzioni} I/O: istruzioni ISA che indirizzano i registri del dispositivo I/O. Sono delle istruzioni privilegiate disponibili solamente in kernel mode (e.g. Intel IA-32).
    \item \textbf{Memory-mapped} I/O: una porzione degli indirizzi fisici è riservata all'I/O. I registri interni dei dispositivi sono mappati su locazioni della memoria principale (a \emph{indirizzi fisici riservati}). I comandi di I/O sono quindi letture/scritture di memoria standard. Le operazioni in quelle posizioni vengono \emph{reindirizzate} ai controller del dispositivo dalla MMU. Gli accessi in modalità utente alle aree mappate in memoria generano \emph{eccezioni} di violazione della memoria.
\end{itemize}

\subsubsection{Ottenere lo stato dell'I/O}
Come fa la CPU a sapere quando i dispositivi di I/O hanno completato le operazioni?
Introduciamo due concetti:
\begin{itemize}
    \item \textbf{Programmed} I/O: la CPU gestisce direttamente le operazioni (read write, transfer) e gli status di I/O. Il dispositivo è quindi \emph{passivo}. La CPU è detta in uno stato di \textbf{polling}, ovvero periodicamente controlla lo stato del dispositivo. È semplice da implementare ma spreca molti cicli di clock.
    \item \textbf{Interrupt-driven} I/O: un interrupt è un evento asincrono proveniente da un dispositivo (e.g. modulo I/O, timer, controller DMA). È un'alternativa al polling. La CPU invia dei comandi ad un dispositivo e nel frattempo fa qualcos'altro. Al termine di ogni ciclo fetch-decode-execute, controlla se sono arrivati interrupt. In caso positivo salva lo stato corrente (passando in privileged-mode), esegue il programma, e poi ripristina il contesto.
\end{itemize}
\begin{note}[Eccezioni]
	A volte le \textbf{eccezioni} sono anche chiamate interruzioni (o comprendono interruzioni). In generale, le eccezioni sono eventi \textbf{sincroni} che interrompono l'esecuzione del programma (e.g. overflow aritmetico, istruzione non definita).
\end{note}

\begin{figure}[h!]
    \centering
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=3cm]{images/programmed-io.png}
        \caption{Programmed IO}
    \end{subfigure}
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=3cm]{images/interrupt-driven-io.png}
        \caption{Interrupt driven IO}
    \end{subfigure}
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=4.5cm]{images/interrupt-manager.png}
        \caption{Interrupt manager}
    \end{subfigure}
\end{figure}

\begin{example}
    Facciamo ora un esempio, assumiamo di avere una CPU ad una velocità di 500MHz ed un costo di polling di 400 cicli. Abbiamo poi un mouse come dispositivo a banda lenta.
    Vogliamo aver un poll di 30 volte al secondo.\\\\
    Per calcolare i cicli al secondo per polling scriviamo (30 poll/s) * 400 = 120000 cycles/s, e la percentuale di cicli spesi
    per polling si calocla fancendo 12K/500M = 0.002\(\%\). Abbiamo dunque un overhead accettabile.\\\\
    Prendiamo ora un disco (che è un dispositivo ad alta lunghezza si banda) che ha 4MB/s di transfer rate e 16B interface.\\
    Per non mancare i dati dobbiamo eseguire il poll abbastanza spesso, quindi (4MB/s)/16B = 250 K/s, vista come percentuale di cicli
    abbiamo 100M / 500 M = 20\(\%\), questo risultato non è accetabile perchè Abbiamo speso il 20\(\%\) dei cicli solo per controllare i registri I/O, non per il trasferimento dei dati
\end{example}

\subsection{Data transfers (DMA)}
Andiamo ora a rispondere all'ultima domanda che ci eravamo posti, come i device di I/O eseguno il trasferimento dei dati?
Sappiamo ora che l'I/O guidato da interrupt elimina i problemi di polling, tuttavia, il sistema operativo deve trasferire i dati una parola alla volta. Questo va bene solo per dispositivi I/O a bassa larghezza di banda (ad es. mouse), per ovviare
a questo problma introduciamo la direct memory access (DMA).\\\\
\begin{figure}[h!]
    \centering
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=3cm]{images/dma-controller.png}
        \caption{DMA controller}
    \end{subfigure}
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=3cm]{images/dma-transfer.png}
        \caption{DMA transfer}
    \end{subfigure}
\end{figure}
Esso è meccanismi che forniscono a un dispositivo di controllo I/O la capacità di trasferire i dati direttamente da e verso la memoria principale senza coinvolgere la CPU. 
DMA disaccoppia il protocollo CPU-memoria dal protocollo memoria-dispositivo I/O. Interrupt utilizzati dal dispositivo I/O per comunicare con la CPU solo al completamento del trasferimento I/O o quando si verifica un errore.\\\\
DMA è implementato con un controller specializzato. Per eseguire DMA, un dispositivo I/O è collegato a un controller DMA: è possibile collegare più dispositivi allo stesso controller. Il controller stesso è visto come un dispositivo I/O mappato in memoria, 
inoltre il controller DMA si occupa dell'arbitrato del bus e del trasferimento dei dati: diventa il master del bus. Il controller DMA e la CPU si contendono il bus di memoria.
Ci sono tre passi nel transfer DMA:
\begin{enumerate}
    \item La CPU imposta DMA fornendo identità, op, indirizzo di memoria e numero di byte da trasferire.
    \item DMA avvia l'operazione sul dispositivo e arbitra la connessione. Trasferisce i dati dal dispositivo o dalla memoria.
    \item Una volta completato il trasferimento DMA, il controller invia un interrupt alla CPU.
\end{enumerate}

\begin{example}
    Facciamo un esempio, assumiamo i seguenti dati: 500Mhz CPU, il device di un disco ha un tempo di trasferimento 4MB/s, 16B di interfaccie
    e un utilizzo di 50\(\%\), la gestione degli interrupt richiede 400 cicli, il trasferimento dei dati richiede 100 cicli, l'installazione DMA richiede 1600 cicli, trasferisce un blocco da 16 KB alla volta.\\\\
    Overhead del processore per I/O guidato da interrupt senza DMA (il processore è coinvolto per ogni trasferimento di dati (16 B)) si calcola facendo 0.5 * (4MB/s) / (16B) * [(400 + 100) cicli / 500M cicli/s] = 12.5 \(\%\).\\\\
    Overhead del processore per I/O guidato da interrupt con trasferimento DMA (Il processore è coinvolto una volta per trasferimento a blocchi (16 KB)) si calcola invece facendo 0.5 * (4M B/s) / (16KB) * [(1600 + 400) / (5ooM cicli/s)] = 0.05 \(\%\)
\end{example}
Notiamo da questo esempio che Senza DMA: il processore avvia tutti i trasferimenti di dati, tutti i trasferimenti passano attraverso la traduzione degli indirizzi (MMU), i trasferimenti possono essere di qualsiasi dimensione e attraversare i limiti della pagina virtuale, 
nessun impatto sulla gerarchia della cache, le cache non contengono mai dati obsoleti.\\\\
Mentre con DMA: il controller DMA avvia i trasferimenti di dati, esiste un altro percorso per il sistema di memoria, potenziali problemi: 
i controller DMA utilizzano indirizzi virtuali o fisici? Cosa succede se scrivono i dati in una posizione di memoria cache?\\\\
Per rispondere alla domanda, quali indirizzi il processore specifica al controller DMA? Abbiamo la virtual DMA e la 
DMA fisica:
\begin{itemize}
    \item Virtual DMA: Il controller DMA deve eseguire internamente la traduzione degli indirizzi utilizzando una piccola cache (TLB) inizializzata dal sistema operativo quando richiede un trasferimento I/O. Complesso ma flessibile (ad esempio, grandi trasferimenti tra pagine).
    \item Physical DMA: Il controller DMA funziona con indirizzi fisici. Trasferimenti alla granularità della pagina, il sistema operativo suddivide i trasferimenti di grandi dimensioni in blocchi delle dimensioni della pagina. Più semplice, ma meno flessibile.
\end{itemize}
\begin{figure}[h!]
    \centering
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=4cm]{images/divice-access.png}
        \caption{Device access}
    \end{subfigure}
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=4cm]{images/kernel-io-structure.png}
        \caption{Kernel IO structure}
    \end{subfigure}
\end{figure}
La DMA ha anche un'integrazione con la cache essendo che la memorizzazione nella cache riduce le istruzioni della CPU e la latenza di accesso ai dati e riduce l'utilizzo della memoria da parte della CPU, lasciando così più larghezza di banda di memoria/bus per i trasferimenti DMA. Ma le cache introducono un problema di coerenza per DMA: se il DMA scrive nella memoria principale, la versione dei dati nella cache è obsoleta. Per le cache write-back, il controller DMA potrebbe leggere i vecchi valori dei dati dalla memoria mentre i dati nella cache hanno il set di bit sporchi. La soluzione è lo svuotamento/invalidamento selettivo delle linee memorizzate nella cache 
coinvolte nei trasferimenti DMA: richiede una logica aggiuntiva per la coerenza della cache HW!\\\\
L'accesso hai device è gestito tramite, uno stack software che fornisce modi per accedere a un'ampia gamma di dispositivi I/O. 
Un'interfaccia comune, in POSIX equivalente all'accesso ai file, in termini di chiamate di sistema 
di apertura/chiusura, lettura/scrittura. Driver di dispositivo per ogni dispositivo specifico, parte superiore HW, 
indipendenti (per migliorare la portabilità), parte inferiore HW-dipendente.
\begin{figure}[h!]
    \centering
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=7cm]{images/device-driver.png}
        \caption{Device driver}
    \end{subfigure}
    \hspace{3cm}
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=4cm]{images/io-request-life-cycle.png}
        \caption{IO request life cycle}
    \end{subfigure}
\end{figure}

