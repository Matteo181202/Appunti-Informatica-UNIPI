% !TeX spellcheck = it_IT
\newpage
\section{Variabili aleatorie}
Le variabili aleatorie sono funzioni dello spazio di probabilità. Permettono di scrivere osservazioni diverse fatte su uno stesso spazio $\Omega$.
\begin{definition}[Variabile aleatoria]
	È una funzione
	\begin{equation}
		X : \Omega \to \mathbb{R}
	\end{equation}
	definita su uno spazio di probabilità.
\end{definition}
\subsection{Legge di una variabile aleatoria}
Ad una variabile aleatoria sono associati eventi del tipo "$X$ prende valori in un insieme $A\subseteq \mathbb{R}$:
\begin{equation*}
	\{X \in A\} = X^{-1}(A)=\{\omega \in \Omega: X(\omega) \in A\}
\end{equation*}
\begin{equation*}
	\mathbb{P}_X(A)=\mathbb{P}(X \in A)=\mathbb{P}(X^{-1}(A))
\end{equation*}

\begin{definition}[Legge di probabilità di una v.a.]
	La funzione $\mathbb{P}_X$ è una probabilità su $\mathbb{R}$ ed è detta \textbf{legge di probabilità} di $X$.
\end{definition}

\begin{note}
	Quando due variabili aleatorie hanno la stessa legge di probabilità sono dette \textbf{equi distribuite}.
\end{note}

\subsection{Tipi di variabili aleatorie}
\subsubsection{Variabili discrete}
\begin{definition}[Variabile aleatoria discreta]
	Una variabile aleatoria è discreta se la sua immagine $X(\Omega) \subset \mathbb{R}$ è un sottoinsieme al più numerabile di $\mathbb{R}$ o se la sua legge di probabilità è discreta.
	Se $A \subseteq \mathbb{R}$ vale
	\begin{equation*}
		p_X(A)=\mathbb{P}(x \in A) = \sum_{x_i \in A}p_X(x_i)
	\end{equation*}
\end{definition}
\subsubsection{Variabili continue}
\begin{definition}[Variabile aleatoria continua]
	Una variabile aleatoria è detta con densità o continua se la sua legge di probabilità è definita da una densità $f$, ovvero se esiste una $f$ tale che
	\begin{equation}
		\mathbb{P}_X(A) = \mathbb{P}\{X \in A\}=\int_{A}f(x)dx
	\end{equation}
	Se $A=[a,b]$ è un segmento, vale
	\begin{equation}
		\mathbb{P}\{X \in A\}=\mathbb{P}(a \leq X \leq b) = \int_{a}^{b} f(x) dx
	\end{equation}
\end{definition}
\subsection{Funzione di ripartizione}
Per studiare una legge di probabilità di una variabile aleatoria è conveniente usare una funzione su $\mathbb{R}$.
\begin{definition}[Funzione di ripartizione]
	La funzione di ripartizione (c.d.f.) su $X$ è
	\begin{equation}
		F_X:\mathbb{R}\to[0,1] \quad\quad F_X(x) = \mathbb{P}\{X \leq x\}
	\end{equation}
\end{definition}

\begin{proposition}
	Data $F=F_X$ la funzione di ripartizione di una variabile aleatoria $X$, valgono:
	\begin{itemize}
		\item $F$ è \textbf{non decrescente}
		\begin{equation}
			x < y \Longrightarrow F(X) \leq F(y)
		\end{equation}
		\item $\lim_{x \to -\infty}=0$, $\lim_{x \to + \infty}F(x) = 1$
		\item $F$ è \textbf{continua} a destra
		\begin{equation}
			\forall x \in \mathbb{R} \quad F(x_n) \to F(x)
		\end{equation}
		per ogni successione $x_n \to x \quad\quad x_n \geq x$
	\end{itemize}
\end{proposition}

\begin{proposition}
	La probabilità che $X$ cada in un dato intervallo $[a,b]$ per $a<b$ è
	\begin{equation}
		\mathbb{P}\{a < X \leq b\}=F(b)-F(a)
	\end{equation}
\end{proposition}

\subsubsection{Funzioni di variabili discrete}
Data una variabile aleatoria discreta $X$, la sua c.d.f. che assume valori $x_1, x_2, \ldots$ è
\begin{equation}
	F_X(t) = \sum_{x_i \leq t}p(x_i)
\end{equation}
Questa è una funzione a \textbf{gradini} che esegue un salto in ogni punto $x$ tale che $\mathbb{P}(X=x)>0$ di ampiezza pari alla probabilità di quel punto. Vale quindi
\begin{equation}
	\mathbb{P}\{X=x\} = F(x) - F_\_(x)
\end{equation}
\subsubsection{Funzioni di variabili continue}
Quando la variabile ha densità $f$ la sua funzione di ripartizione (\textbf{continua}) è
\begin{equation}
	F(x)=\int_{-\infty}^{x}dt
\end{equation}
o nel caso in cui è \textbf{continua a tratti} si ottiene:
\begin{equation}
	f(x) = \frac{dF(x)}{dx}
\end{equation}

\subsection{$\beta$-quantile}
\begin{definition}[$\beta$-quantile]
	Data una variabile aleatoria $X$ ed un numero $0 < \beta < 1$ il $\beta$-quantile è:
	\begin{equation}
		r_\beta = \inf\{r \in \mathbb{R} : F(r) \geq \beta\} \quad\quad \beta \in (0,1)
	\end{equation}
\end{definition}
\begin{definition}[Inversa generalizzata]
	L'inversa generalizzata di $F$ è
	\begin{equation}
		F^{\leftarrow}:(0,1) \to \mathbb{R} \quad\quad F^{\leftarrow}(t) = \inf\{r \in \mathbb{R} : F(r) \geq t\}
	\end{equation}
\end{definition}
\begin{proposition}
	Valgono:
	\begin{itemize}
		\item Se $F$ è strettamente crescente $F^{\leftarrow} = F^{-1}$
		\item $F^{\leftarrow}$ è sempre \textbf{non decrescente}
		\item $F^{\leftarrow}(F(t))\leq t \quad\quad \forall t \in \mathbb{R}$
		\item $F(F^{\leftarrow}(t)) \geq t \quad\quad \forall t \in \mathbb{R}$
		\item $F^{\leftarrow}(t) \leq s \Longleftrightarrow F(s) \geq t$
	\end{itemize}
\end{proposition}

\subsection{Variabili discrete notevoli}
\subsubsection{Binomiali}
\begin{equation}
	B(n,p)
\end{equation}
Date $n$ prove ripetute di un esperimento con \textbf{due esiti}, chiamiamo uno di questi \textit{successo} con probabilità $0 < p < 1$. Sia $X$ la variabile che conta il numero di successi ($0, 1, \ldots,n$). Vale:
\begin{equation}
	\mathbb{P}(X=h)=\binom{n}{h}p^h(1-p)^{n-h} \quad\quad 0 \leq h \leq n
\end{equation}
Ovvero dati $h$ successi e $n-h$ insuccessi, calcoliamo il numero di modi di disporre i successi.

\begin{observation}
	Date due successioni $x_1,x_2, \ldots \in \mathbb{R}$ e $p_1, p_2, \ldots \in [0, \infty)$ tale che $\sum_{i=1}^{\infty}p_1 = 1$, possiamo definire una variabile discreta tramite
	\begin{equation}
		\Omega = \mathbb{N} \quad\quad \mathbb{P}(\{k\})=p_k \quad\quad X(k) = x_k
	\end{equation}
	ovvero dove
	\begin{equation*}
		\mathbb{P}_X(k) = \mathbb{P}(X = x_k) = p_k
	\end{equation*}
\end{observation}
Un caso particolare delle variabili binomiali è quando $n=1$, ovvero le variabili di \textbf{Bernoulli}.

\subsubsection{Geometriche}
\begin{equation}
	G(p)
\end{equation}
Consideriamo la stessa situazione delle variabili binomiali ma definiamo $X$ come l'istante del primo successo, ovvero il numero $h$ tale che alla prova $h$-esima si verifichi il primo successo. Vale:
\begin{equation}
	P(X=h)=(1-p)^{h-1}p \quad\quad h \in \mathbb{N}_0
\end{equation}
Questo corrisponde a dire, dato l'evento $A_i$ successo della prova $i$-esima,
\begin{equation*}
	\mathbb{P}(X=h) = \mathbb{P}(A^c_1 \cap A^c_2 \cap \ldots \cap A^c_{h-1} \cap A_h) = \mathbb{P}(A^c_1) \cdot \mathbb{P}(A^c_2) \cdot \ldots \cdot \mathbb{P}(A^c_{h-1}) \cdot \mathbb{P}(A_h) = (1-p)^{h-1}p
\end{equation*} 

\begin{observation}[Assenza di memoria]
	Le variabili geometriche hanno assenza di memoria, ovvero
	\begin{equation}
		\mathbb{P}\{X=n+h \vert X >n \} = \mathbb{P}\{X=h\}
	\end{equation}
\end{observation}

\subsubsection{Ipergeometriche}
\begin{equation}
	I(n,h,r)
\end{equation}
Prendiamo ad esempio un'urna con $n$ biglie di cui $0 \leq h \leq n$ sono bianche e $n-h$ nere. Estraiamo $r \leq n$ biglie senza reinserirle. La variabile che conta quante biglie estratte $k$ sono bianche ha funzione di massa
\begin{equation}
	\mathbb{P}(X=k) = \frac{\binom{h}{k}\binom{n-h}{r-k}}{\binom{n}{r}} \quad\quad k=0,\ldots, h
\end{equation}
\begin{proposition}[Identità di Vandermonde]
	Date $k$ biglie bianche e $r-k$ nere, il numero di scelte possibili è
	\begin{equation*}
		\binom{h}{k}\binom{n-h}{r-k}
	\end{equation*}
	mentre il numero totale di scelte è 
	\begin{equation*}
		\binom{n}{r}
	\end{equation*}
	Otteniamo quindi
	\begin{equation}
		\sum_{k=0}^{h} \binom{h}{k}\binom{n-h}{r-k} = \binom{n}{r}
	\end{equation}
	che mostra anche $\sum_{k=0}^{h}\mathbb{P}(X=k) = 1$
\end{proposition}

\subsubsection{Poisson}
\begin{equation}
	P(\lambda)
\end{equation}
Una variabile è di Poisson quando
\begin{equation}
	\mathbb{P}(X=h)=e^{-\lambda}\frac{\lambda^h}{h!} \quad\quad h \in \mathbb{N}, \lambda>0
\end{equation}
Dato che è una buona approssimazione di una distribuzione binomiale quando $n$ è grande, $p$ è piccolo $np$ è circa $\lambda$, possiamo dire che conta il numero di successi quando il numero di prove è alto e la probabilità è bassa. Viene anche detta degli \textbf{eventi rari} (eruzioni vulcaniche, particelle $\alpha$ emesse da una sorgente radioattiva).

\subsection{Variabili con densità notevoli}
Consideriamo i casi in cui esiste una funzione di densità non negativa di integrale unitario su tutto $\mathbb{R}$ $f_X$ tale che
\begin{equation}
	\mathbb{P}(X \in [a,b]) = \mathbb{P}(X \in (a,b)) = \int_{a}^{b} f_X(t)dt
\end{equation}

\subsubsection{Uniformi su intervalli}
Dati due numeri reali $a < b$, la densità uniforme sull'intervallo $[a,b]$ è
\begin{equation}
	f(t) = \begin{cases}
		\frac{1}{b-a} & a < t < b\\
		0 & \text{altrove}
	\end{cases}
\end{equation}
La c.d.f. è
\begin{equation}
	F(t)=\begin{cases}
		0 & t \leq a \\
		\frac{t}{b-a} & 0 < t \leq b \\
		1 & t>b
	\end{cases}
\end{equation}
Ad esempio un numero preso a caso tra $0$ e $1$.

\subsubsection{Esponenziali}
Dato il parametro $\lambda>0$ la densità è
\begin{equation}
	f(x)=\begin{cases}
		\lambda e^{-\lambda t} & t >0 \\
		0 & t \leq 0
	\end{cases}
\end{equation}
La c.d.f. è
\begin{equation}
	F(t) = \begin{cases}
		1-e^{-\lambda t} & t>0\\
		0 & t \leq 0
	\end{cases}
\end{equation}
Descrive ad esempio il tempo di attesa tra due eventi aleatori, come tra le chiamate di un call center.
\begin{observation}
	Questa variabile prende solo valori positivi
	\begin{equation*}
		\mathbb{P}\{X \leq 0\}= 0
	\end{equation*}
\end{observation}

\subsubsection{Pareto}
Dati $x_m, \alpha > 0$ la densità è
\begin{equation}
	f(t) = \begin{cases}
		\alpha x_m^\alpha t^{-1-\alpha} & t> x_m \\
		0 & t \leq x_m
	\end{cases}
\end{equation}
La densità è non nulla dopo la soglia $x_m$ e al diminuire di $\alpha$ ha una coda sempre più pesante. La c.d.f. è
\begin{equation}
	F(t) = \begin{cases}
		1 & t < x_m \\
		1-(\frac{x_m}{t})^\alpha & t \geq x_m
	\end{cases}
\end{equation}
Chiamata anche \textbf{power law}, serve a descrivere fenomeni in cui eventi estremi hanno una buona probabilità di avvenire, come la distribuzione della ricchezza nella società.

\subsubsection{Gaussiane standard}
Viene indicata con $N(0,1)$ e ha densità
\begin{equation}
	\varphi(x) = \frac{1}{\sqrt{2\pi}}e^{\frac{-x^2}{2}}
\end{equation}
e c.d.f.
\begin{equation}
	\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{\frac{-t^2}{2}}dt
\end{equation}

\begin{observation}
	Questa densità è una funzione pari ($\varphi(x) = \varphi(-x)$). Di conseguenza, dati $x \in \mathbb{R}$ e $0 < \alpha < 1$, si ha
	\begin{equation}
		\Phi(-x) = 1 - \Phi(x) \quad\quad q_{1-\alpha} = -q_\alpha
	\end{equation}
	Di conseguenza, se $X$ è una variabile aleatoria $N(0,1)$, valgono
	\begin{equation}
		\mathbb{P}\{-t \leq X \leq t\} = \Phi(t) - \Phi(-t) = 1\Phi(t) -1
	\end{equation}
	\begin{equation}
		\Phi(0) = \mathbb{P}\{X \geq 0\} = \mathbb{P}\{X \leq 0\} = \frac{1}{2}
	\end{equation}
\end{observation}
\subsubsection{Gaussiane non standard}
\begin{equation}
	N(m, \sigma^2)
\end{equation}
Data $X$ una variabile Gaussiana Standard, dati $\sigma >0$ e $m \in \mathbb{R}$, consideriamo la variabile aleatoria $Y = \sigma X +m$. La sua densità è
\begin{equation}
	f_Y(t) = \frac{1}{\sigma}f_X\bigg(\frac{t-m}{\sigma}\bigg) = \frac{1}{\sqrt{2 \pi}\sigma}e^{-\frac{(t-m)^2}{2\sigma^2}}
\end{equation}
mentre la sua c.d.f. è
\begin{equation}
	F_Y(t)= \mathbb{P}\{Y \leq t\} = \mathbb{P}\{\sigma X + m \leq t\} = \mathbb{P}\bigg(X \leq \frac{t-m}{\sigma}\bigg) = \Phi \bigg(\frac{t-m}{\sigma}\bigg)
\end{equation}

\begin{observation}
	Vale:
	\begin{equation}
		\mathbb{P}\{a < Y < b\} = \mathbb{P}\bigg\{\frac{a-m}{\sigma} < X < \frac{b-m}{\sigma}\bigg\}
	\end{equation}
\end{observation}

\subsection{Trasformazioni di variabili con densità}
Data la variabile aleatoria $X: \Omega \to \mathbb{R}$ con densità $f$ e una funzione $h: \mathbb{R} \to \mathbb{R}$, vogliamo la densità della variabile aleatoria composta 
\begin{equation*}
	Y: \Omega \to \mathbb{R} \quad\quad Y=h \circ X
\end{equation*}
Se è possibile calcolare la c.d.f. di $Y$
\begin{equation*}
	F_Y(y)=\mathbb{P}\{Y \leq y\} = \mathbb{P}\{h(X) \leq y\}
\end{equation*}
ed è \textbf{continua} e differenziabile, allora è sufficiente derivarla per ottenere la densità di $Y$.
\begin{proposition}[Cambio di variabile]
	Data $X$ una variabile aleatoria con densità $f_X$, supportata su un intervallo aperto $A$ ($f_X$ nulla su $A^c$). Data una funzione $h: A \to B$, con $B$ un intervallo aperto, \textbf{biunivoca}, \textbf{differenziabile} e con \textbf{inversa differenziabile}. Allora $Y = h \circ X$ ha densità
	\begin{equation}
		f_Y(y)=\begin{cases}
			f_X(h^{-1}(y)) \cdot \bigg\lvert \frac{dh^{-1}(y)}{dy}\bigg\rvert & y \in B\\
			0 & y \notin B
		\end{cases}
	\end{equation}
\end{proposition}

\subsection{Valore atteso}
Applichiamo il concetto di \textit{media campionaria} e di \textit{varianza campionaria} anche alle variabili aleatorie.
\begin{definition}[Valore atteso]
	Data una variabile discreta $X$ con funzione di massa $p_X$, si dice che questa ha valore atteso se
	\begin{equation*}
		\sum_{i}\lvert x_i \rvert p_X(x_i) < +\infty
	\end{equation*}
	e vale
	\begin{equation}
		\mathbb{E}[X]=\sum_{i}x_ip_X(x_i)
	\end{equation}
	Se $X$ è con densità e
	\begin{equation*}
		\int_{-\infty}^{+\infty} \lvert x \rvert f_X(x) dx < + \infty
	\end{equation*}
	allora il valore atteso è
	\begin{equation}
		\mathbb{E}[X]=\int_{-\infty}^{+\infty}t f_X(t)dt
	\end{equation}
\end{definition}

\begin{note}
	Il valore atteso è anche chiamato \textbf{momento primo} o speranza matematica.
\end{note}

\begin{observation}
	Dato che il valore atteso dipende solo dalla funzione di massa o dalla densità, ovvero solo dalla legge $\mathbb{P}_X$ di $X$, allora se due variabili sono \textbf{equi distribuite} hanno anche lo stesso valore atteso.
\end{observation}

\begin{observation}
	Se $X$ prende solo valori positivi, possiamo ammettere che $E[X]$ possa assumere il valore $+\infty$.\\
	Nel caso discreto vuol dire che $x_1, x_2, \ldots$ sono sempre positivi e quindi ha senso
	\begin{equation*}
		\mathbb{E}[X]=\sum_{i=1}^{+\infty} x_i p(x_i)
	\end{equation*}
	Nel caso con densità significa che $f(x)=0 \quad x<o$ e quindi ha senso
	\begin{equation*}
		\mathbb{E}[X] = \int_{0}^{+\infty} xf(x)dx \in [0, +\infty]
	\end{equation*}
	In generale
	\begin{equation}
		\mathbb{E}[\lvert X \rvert] < + \infty
	\end{equation}
\end{observation}

\begin{proposition}
	Valgono:
	\begin{itemize}
		\item $\forall a,b \in \mathbb{R}$ valgono $\mathbb{E}[aX+b]=a\mathbb{E}[X] + b$ e $\mathbb{E}[b] = b$
		\item $\lvert \mathbb{E}[X]\rvert \leq \lvert \mathbb{E}[\lvert X \rvert]$
		\item $\mathbb{P}(X \geq 0)=1 \Longrightarrow \mathbb{E}[X] \geq 0$
	\end{itemize}
\end{proposition}

\subsubsection{Valore atteso di trasformazioni}
Supponiamo di voler calcolare il valore atteso di trasformazioni di una variabile aleatoria $X$, ovvero $Y=g(x) \quad g:\mathbb{R} \to \mathbb{R}$.
\begin{proposition}[Valore atteso di trasformazioni discrete]
	Se $X$ è discreta e
	\begin{equation*}
		\sum_{i} \lvert g(x_i) \rvert p(x_i) < +\infty
	\end{equation*}
	allora
	\begin{equation}
		\mathbb{E}[g(X)] = \sum_{i} g(x_i)p(x_i)
	\end{equation}
\end{proposition}
\begin{proposition}[Valore atteso di trasformazioni con densità]
	Se $X$ è con densità e
	\begin{equation*}
		\int_{-\infty}^{+\infty}\lvert g(x)\rvert f(x)dx < +\infty
	\end{equation*}
	allora
	\begin{equation}
		\mathbb{E}[g(X)] = \int_{-\infty}^{+\infty} g(x) f(x)dx
	\end{equation}
\end{proposition}
	
\subsubsection{Momenti}
\begin{definition}[Momento]
	La variabile aleatoria $X$ ammette momento di ordine $n=1,2,\ldots$ se
	\begin{equation*}
		\mathbb{E} [\lvert X \rvert] < + \infty
	\end{equation*}
	e in quel caso si chiama $\mathbb{E}[X^n]$ il momento di ordine $n$.
\end{definition}

\begin{observation}
	Se una variabile discreta assume solo valori finiti, tutti i momenti sono finiti. Se una variabile con densità è diversa da $0$ solo su un intervallo limitato, tutti i momenti sono finiti.
\end{observation}

\begin{proposition}
	Siano $1 \leq m < n$
	\begin{equation}
		\mathbb{E}[\lvert X \rvert ^n] < +\infty \Longrightarrow \mathbb{E}[\lvert X \rvert ^m] < +\infty
	\end{equation}
	Ovvero se una variabile aleatoria ammette momenti fino a $n$, ammetterà anche tutti i suoi precedenti. In particolare vale la \textbf{disuguaglianza di Jensen}:
	\begin{equation}
		\mathbb{E}[\lvert X \rvert^m]^{\frac{1}{m}} \leq \mathbb{E}[\lvert X \rvert^n]^{\frac{1}{n}}
	\end{equation}
\end{proposition}

\begin{proposition}[Disuguaglianza di Markov]
	Se $X$ è una variabile aleatoria a valori positivi e $a>0$ vale
	\begin{equation}
		a\mathbb{P}\{X \geq a\} \leq \mathbb{E}[X]
	\end{equation}
\end{proposition}

\subsubsection{Varianza di una variabile aleatoria}
\begin{definition} [Varianza]
	Se $X$ ammette momento secondo, la sua varianza è
	\begin{equation}
		Var(X) = \mathbb{E}[(X-\mathbb{E}[X])^2] = \mathbb{E}[X^2]-\mathbb{E}[X]^2
	\end{equation}
	e lo \textbf{scarto quadratico medio} o \textbf{deviazione standard} è
	\begin{equation}
		\sigma(X) = \sqrt{Var(X)}
	\end{equation}
\end{definition}

\begin{proposition}[Disuguaglianza di Chebyshev]
	Data $X$ una variabile aleatoria e $d>0$, vale
	\begin{equation}
		\mathbb{P}\{\lvert X - \mathbb{E}\rvert > d\} \leq \frac{Var(X)}{d^2}
	\end{equation}
\end{proposition}

\begin{observation}
	La varianza di una variabile $X$ vale $0$ solo se questa è costante tranne che per un insieme trascurabile
	\begin{equation*}
		\mathbb{P}\{\lvert X - \mathbb{E}[X] \rvert \neq 0\} = 0
	\end{equation*}
\end{observation}

\subsubsection{Momenti notevoli}
Vediamo i momenti delle variabili notevoli.
\paragraph{Variabili binomiali}
Per una variabile di Bernoulli vale
\begin{equation}
	\mathbb{E}[X^k] = p \quad\quad Var(X)=p-p^2=p(1-p) \quad\quad k \geq 1
\end{equation}
Dato che una variabile Binomiale può essere vista come somma di variabili di Bernoulli, vale
\begin{equation}
	\mathbb{E}[X] = np \quad\quad Var(X) = np(1-p)
\end{equation}

\paragraph{Variabili di Poisson}
Dato che assumono solo valori positivi:
\begin{equation}
	\mathbb{E}[X] = \sum_{h=0}^{+\infty}he^{-\lambda}\frac{\lambda^h}{h!} = \lambda e^{-\lambda}\sum_{h=1}^{+\infty}\frac{\lambda{h-1}}{(h-1)!} = \lambda e^{-\lambda}\sum_{k=0}^{+\infty}\frac{\lambda^k}{k!}=\lambda
\end{equation}
\begin{equation}
	\mathbb{E}[X^2]=\lambda + \lambda^2 \quad\quad Var(X)=\lambda
\end{equation}

\paragraph{Variabili uniformi su intervalli finiti}
Data una variabile $X$ con densità uniforme su $[a,b]$, vale:
\begin{equation}
	\mathbb{E}[X] = \int_{a}^{b}\frac{x}{b-a}dx = \frac{x^2}{2(b-a)}\bigg\vert^b_a = \frac{b^2-a^2}{2(b-a)}=\frac{a+b}{2}
\end{equation}
\begin{equation}
	\mathbb{E}[X^2] = \int_{a}^{b}\frac{x^2}{b-a}dx = \frac{x^3}{3(b-a)}\bigg\vert^b_a = \frac{b^3-a^3}{3(b-a)}=\frac{a^2+ab+b^2}{3} \quad\quad Var(X) = \frac{(b-a)^2}{12}
\end{equation}

\paragraph{Variabili esponenziali}
Vale:
\begin{equation}
	\mathbb{E}[X] = \int_{0}^{+\infty}\land x e^{-\lambda x}dx=\frac{1}{\lambda}
\end{equation}
e più in generale
\begin{equation}
	\mathbb{E}[X^n]=\frac{n!}{\lambda^n}
\end{equation}
Quindi anche
\begin{equation}
	Var(X) = \frac{1}{\lambda^2}
\end{equation}

\paragraph{Variabili Gaussiane standard}
Se $X$ è Gaussiana Standard, notiamo che possiede tutti i momenti
\begin{equation}
	\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}\lvert x\rvert^ne^{-\frac{x^2}{2}} dx < +\infty
\end{equation}
I momenti dispari valgono:
\begin{equation}
	\mathbb{E}[X^{2h+1}] = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^ne^{-\frac{x^2}{2}}dx = \lim_{M \to \infty}\frac{1}{\sqrt{2\pi}}\int_{-M}^{+M}x^ne^{-\frac{x^2}{2}}dx=0
\end{equation}
mentre quelli pari, guardando ad esempio il momento secondo
\begin{equation}
	\mathbb{E}[X^2]=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^2e^{-\frac{x^2}{2}}dx = \frac{-xe^{-\frac{x^2}{2}}}{\sqrt{2\pi}}\bigg\vert^{+\infty}_{-\infty}+\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{x^2}{2}}dx = 1 \quad\quad Var(X)=1
\end{equation}
e più in generale
\begin{equation}
	\mathbb{E}[X^{2h+2}]=(2h+1)\mathbb{E}[X^{2h}]
\end{equation}

\paragraph{Variabili Gaussiane}
Data $Y=\sigma X + m$, per linearità del valore atteso
\begin{equation}
	\mathbb{E}[Y] = \mathbb{E}[\sigma X + m] = m \quad\quad Var(Y)=Var(\sigma X +m)=\sigma^2Var(X) = \sigma^2
\end{equation}

\subsection{Variabili doppie}
Dato $\Omega$ uno spazio di probabilità e $X,Y:\Omega \to \mathbb{R}$, il vettore $(X,Y)$ può essere visto come una funzione
\begin{equation}
	\Omega \ni \omega \mapsto (X(\omega),Y(\omega))\in \mathbb{R}^2
\end{equation}
La sua legge è una probabilità sui sottoinsiemi $A \subseteq \mathbb{R}^2$
\begin{equation}
	\mathbb{P}_{X,Y)}(A) = \mathbb{P}((X,Y) \in A) = \mathbb{P}\{\omega \in \Omega : (X(\omega), Y(\omega)) \in A\}
\end{equation}

\begin{observation}[Insieme rettangolare]
	Se $A=A_1 \times A_2$ è un sottoinsieme rettangolare vale
	\begin{equation}
		\{(X,Y) \in A\} = \{X \in A_1, Y \in A_2\}
	\end{equation}
\end{observation}

\begin{note}
	Con la virgola indichiamo l'intersezione di due condizioni
	\begin{equation*}
		\{X \in A_1, Y \in A_2\} = \{X \in A_1\} \cap \{Y \in A_2\} = X^{-1}(A_1) \cap Y^{-1}(A_2) = (X,Y)^{-1}(A_1 \times A_2)
	\end{equation*}
\end{note}

\subsubsection{Distribuzioni marginali}
Data una variabile doppia $(X,Y)$ possiamo considerare separatamente le leggi delle due componenti $\mathbb{P}_X$ e $\mathbb{P}_Y$. Queste sono dette \textbf{leggi marginali}.\\
Se $I \subseteq \mathbb{R}$, valgono
\begin{equation}
	\mathbb{P}_X(I)=\mathbb{P}_{(X,Y)}(I \times \mathbb{R}) \quad\quad\quad \mathbb{P}_Y(I)=\mathbb{P}_{(X,Y)}(\mathbb{R}\times I)
\end{equation}

Le distribuzioni marginali non contengono tutta l'informazione della legge $\mathbb{P}_{(X,Y)}$ e di conseguenza non si può ricostruire univocamente dalle prime. L'idea è che la legge totale codifica anche le relazioni tra le due leggi, cosa che le marginali non fanno

\subsubsection{Variabili doppie discrete}
Una variabile doppia $(X,Y)$ è discreta se la sua immagine è concentrata in un insieme finito o numerabile di punti $(x_i, y_j)$. La sua \textbf{distribuzione di probabilità} è
\begin{equation}
	p(x_i,y_j) = \mathbb{P}(X=x_i, Y=y_j)
\end{equation}
e se $A\subseteq \mathbb{R}^2$
\begin{equation}
	\mathbb{P}_{(X,Y)}(A) = \mathbb{P}\{(X,Y) \in A\} = \sum_{(x_i, y_j) \in A}p(x_i, y_j)
\end{equation}

\begin{proposition}
	Se una variabile doppia è discreta con funzione di massa, lo sono anche le sue componenti
	\begin{equation}
		p_X(x_i) = \sum_{j=1}^{+\infty} p(x_i,y_j) \quad\quad p_X(y_j) = \sum_{i=1}^{+\infty} p(x_i,y_j)
	\end{equation}
\end{proposition}
\subsubsection{Variabili doppie con densità}
Una variabile doppia $(X,Y)$ è con densità se esiste una funzione $f : \mathbb{R}^2 \to [0,\infty)$ integrabile e con $\int\int_{\mathbb{R}^2}f(x,y)dxdy=1$ tale che valga
\begin{equation}
	\mathbb{P}_{(X,Y)}(A) = \mathbb{P}\{(X,Y) \in A\} = \int\int_A f(x,y) dxdy \quad\quad A \subseteq \mathbb{R}^2
\end{equation}

\begin{theorem}[Teorema di Fubini-Tonelli]
	Dato un insieme rettangolare $A = A_1 \times A_2$ vale
	\begin{equation}
		\int\int_A f(x,y)dxdy = \int_{A_1} \bigg(\int_{A_2} f(x,y)dy\bigg)dx =  \int_{A_2} \bigg(\int_{A_1} f(x,y)dx\bigg)dy 
	\end{equation}
\end{theorem}

\begin{proposition}
	Se una variabile doppia ha densità, anche le sue componenti la hanno
	\begin{equation}
		f_X(x) = \int_{-\infty}^{+\infty}f(x,y)dy \quad\quad f_Y(y) = \int_{-\infty}^{+\infty}f(x,y)dx
	\end{equation}
\end{proposition}

\begin{observation}
	A differenza del caso discreto se $X$ e $Y$ sono con densità non è detto che anche $X,Y)$ la abbia. Ad esempio $(X,X)$.
\end{observation}

\subsection{Indipendenza di variabili aleatorie}
\begin{definition}[Variabili aleatorie indipendenti]
	Le variabili aleatorie $X_1, \ldots, X_n:\Omega \to \mathbb{R}$ si dicono indipendenti se, presi comunque $A_1, \ldots, A_n \subseteq \mathbb{R}$ vale
	\begin{equation}
		\mathbb{P}(X_1 \in A_1, \ldots, X_n \in A_n) = \mathbb{P}(X_1 \in A_1) \cdot \ldots \cdot \mathbb{P}(X_n \in A_n)
	\end{equation} 
\end{definition}

\subsubsection{Indipendenza di variabili doppie}
\begin{proposition}[Indipendenza di variabili doppie discrete]
	Date due variabili discrete $X$ e $Y$ con immagine nei punti $x_i$ e $y_j$, sono indipendenti se e solo se vale
	\begin{equation}
		p(x_i, y_j) = p_X(x_i) \cdot p_Y(y_j) \quad\quad \forall(x_i, y_j)
	\end{equation}
\end{proposition}

\begin{proposition}[Indipendenza di variabili doppie con densità]
	Date due variabili $X$ e $Y$ tale che $(X,Y)$ abbia densità, sono indipendenti se e solo se vale
	\begin{equation}
		f(x,y) = f_X(x) \cdot f_Y(y) \quad\quad \forall(x,y)
	\end{equation}
\end{proposition}

\begin{observation}
	Due variabili aleatorie doppie possono avere le stesse distribuzioni marginali ma essere diverse, ad esempio perché in un caso le componenti sono indipendenti e nell'altro no.
\end{observation}

\subsubsection{Indipendenza di funzioni di variabili indipendenti}
Funzioni di più variabili indipendenti sono indipendenti se la stessa variabile non compare in due funzioni diverse.

\begin{proposition}
	Se $X,Y:\Omega \to \mathbb{N}$ sono variabili discrete a valori naturali e indipendenti e sia $Z=X+Y$ si ha
	\begin{equation}
		p_Z(n) = \sum_{h=0}^{n}p_X(h) \cdot p_Y(n-h)
	\end{equation}
	In particolare se $X$ e $Y$ sono binomiali $B(n,p)$ e $B(m,p)$, allora $Z=X+Y$ è binomiale $B(n+m,p)$.
\end{proposition}
\begin{proposition}
	Se $X$ e $Y$ sono variabili con densità e indipendenti e sia $Z=X+Y$ si ha
	\begin{equation}
		f_Z(z)=\int_{-\infty}^{+\infty}f_X(x)f_Y(z-x)dx = \int_{-\infty}^{+\infty}f_Y(y)f_X(z-y)dy
	\end{equation}
	In particolare se $X$ e $Y$ sono Gaussiane $N(m_1,\sigma_1^2)$ e $N(m_2,\sigma_2^2)$, allora $Z=X+Y$ è Gaussiana $N(m_1+m_2, \sigma_1^2+\sigma_2^2)$.
\end{proposition}

\begin{proposition}
	Se $X$ e $Y$ sono variabili aleatorie indipendenti, allora per tutte le funzioni $h,k: \mathbb{R} \to \mathbb{R}$, anche $h(X)$ e $k(Y)$ lo sono.
\end{proposition}

\subsection{Correlazione}
\begin{proposition}
	Date due variabili aleatorie $X$ e $Y$ con valore atteso, allora $X+Y$ ha valore atteso e valgono:
	\begin{itemize}
		\item $\mathbb{E}[X+Y] = \mathbb{E}[X] + \mathbb{E}[Y]$
		\item $X \geq Y \Longrightarrow \mathbb{E}[X] \geq \mathbb{E}[Y]$
	\end{itemize}
\end{proposition}
\begin{proposition}
	Date due variabili aleatorie $X$ e $Y$ con valore atteso e \textbf{indipendenti}, allora $XY$ ha valore atteso e vale:
	\begin{equation}
		\mathbb{E}[XY] = \mathbb{E}[X] \cdot \mathbb{E}[Y]
	\end{equation}
\end{proposition}

\begin{proposition}
	Se $X$ e $Y$ sono variabili aleatorie con valore atteso e \textbf{indipendenti}, allora per tutte le funzioni $h,k: \mathbb{R} \to \mathbb{R}$, vale
	\begin{equation}
		\mathbb{E}[h(X)k(Y)]=\mathbb{E}[h(X)]\cdot\mathbb{E}[k(Y)]
	\end{equation}
\end{proposition}

\begin{proposition}[Disuguaglianza di Schwartz]
	Se $X$ e $Y$ hanno valore atteso, non è detto che il loro prodotto $XY$ lo abbia ma se hanno momento secondo allora il loro prodotto ha valore atteso. Questo deriva da
	\begin{equation}
		\mathbb{E}[\lvert XY \rvert] \leq \sqrt{\mathbb{E}[X^2]} \cdot \sqrt{\mathbb{E}[Y^2]}
	\end{equation}
\end{proposition}

\subsection{Covarianza}
\begin{definition}[Covarianza]
	La covarianza tra due variabili aleatorie $X$ e $Y$ con momento secondo finito è una misura della presenza di una relazione lineare tra le due e vale
	\begin{equation}
		Cov(X,Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y-\mathbb{E}[Y])] = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]
	\end{equation}
	Quando vale $0$ le variabili sono \textbf{scorrelate}.
\end{definition}